{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenwerte und Eigenvektoren\n",
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Notebook werden zunächst die grundlegenden Konzepte von Eigenwerten und Eigenvektoren erörtert, die für das Verständnis linearer Abbildungen unerlässlich sind. Anschließend wird die Bedeutung dieser Konzepte in verschiedenen Abbildungen wie Rotationen, Kompressionen, Expansionen und Scherungen diskutiert. \n",
    "\n",
    "Ein weiterer Schwerpunkt liegt auf der numerischen Berechnung von Eigenwerten und Eigenvektoren, einem wichtigen Aspekt in technischen und wissenschaftlichen Anwendungen. Zudem wird die Singulärwertzerlegung (SVD) eingeführt, ein leistungsfähiges Werkzeug in der numerischen linearen Algebra, das eine geeignete Zerlegung von Matrizen ermöglicht. \n",
    "\n",
    "Abschließend wird die Beziehung zwischen der Summe der Eigenwerte einer Matrix und ihrer Spur beleuchtet, was wesentliche Einblicke in Matrixeigenschaften bietet."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Python Grundlagen: </b>  /<br>\n",
    "<b> Math. Grundlagen: </b>  Matrizen, Vektoren, lineare Gleichungssysteme <br>\n",
    "\n",
    "Inhaltsverzeichniss:\n",
    "\n",
    "<ul>\n",
    " <li><a href=\"#1\">Einführung in Eigenwerte und Eigenvektoren</a></li>\n",
    " <li><a href=\"#2\">Physikalische Interpretation von Eigenwerten und Eigenvektoren </a></li>\n",
    " <li><a href=\"#3\">Numerische Berechnung von Eigenwerten und Eigenvektoren</a></li>\n",
    " <li><a href=\"#4\">Singulärwertzerlegung (SVD)</a></li>\n",
    " <li><a href=\"#5\">Spur und Eigenwerte</a></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import der benötigten Module\n",
    "%pip install -q ipywidgets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as mtransforms\n",
    "import matplotlib.patches as patches\n",
    "from ipywidgets import interactive, widgets, interact_manual,interact\n",
    "import math\n",
    "import pandas as pd\n",
    "import sympy\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einführung in Eigenwerte und Eigenvektoren <a id=\"1\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die lineare Algebra findet grundlegend in verschiedenen Wissenschafts- und Ingenieursbereichen Anwendung. Unter ihren zahlreichen Konzepten stechen Eigenwerte und Eigenvektoren aufgrund ihrer Anwendungsbreite und theoretischen Bedeutung hervor. Einige ihrer Schlüsselanwendungen sind nachfolgend aufgelistet:\n",
    "\n",
    "1. **Quantenmechanik**: In der Quantenmechanik spielen Eigenwerte und Eigenvektoren eine entscheidende Rolle für das Verständnis beobachtbarer, physikalischer Eigenschaften, wie Energiezustände von Systemen.\n",
    "\n",
    "2. **Schwingungsanalyse**: Im Ingenieurwesen sind Eigenwerte und Eigenvektoren wesentlich für die Analyse von natürlichen Frequenzen und Schwingungsmoden, was für die Konstruktion stabiler Strukturen und Systeme unerlässlich ist.\n",
    "\n",
    "3. **Hauptkomponentenanalyse (PCA)**: In der Datenwissenschaft sind Eigenwerte und Eigenvektoren zentral für die PCA (engl. <i>Principal Component Analysis</i>), eine Technik zur Dimensionsreduktion bei gleichzeitiger Erhaltung möglichst großer Variabilität in gegebenen Daten.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition von Eigenwerten und Eigenvektoren"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Eigenwerte und Eigenvektoren sind zentrale Begriffe in der linearen Algebra und haben spezifische Bedeutungen und Funktionen:\n",
    "\n",
    "1. **Eigenvektor**: Ein Eigenvektor einer reellen $n \\times n$-Matrix $A$ ist ein Vektor $v \\in \\mathbb{R}^n - \\left\\{ 0 \\right\\}$, der unter der linearen Abbildung $A$ auf ein Vielfaches von sich selbst abgebildet wird. Formal gilt: Der Vektor $v$ heißt Eigenvektor von $A$, wenn es ein $\\lambda \\in \\mathbb{R}$ derart gibt, dass\n",
    "\n",
    "    $ Av = \\lambda v $\n",
    "    \n",
    "    gilt.\n",
    "2. **Eigenwert**: Der Skalar $ \\lambda \\in \\mathbb{R} $, um den der Eigenvektor $v$ vervielfacht wird, sodass die obige Gleichung gilt.\n",
    "\n",
    "\n",
    "\n",
    "Die Berechnung von Eigenwerten erfolgt in der Regel durch folgende Schritte:\n",
    "\n",
    "1. **Charakteristisches Polynom**: Ausgehend von der Eigenwertgleichung $ Av = \\lambda v $ oder umgeformt $ (A - \\lambda I)v = 0 $, wobei $ I $ die Einheitsmatrix ist, ergibt sich das charakteristische Polynom durch die Berechnung der Determinante $ \\text{det}(A - \\lambda I) $.\n",
    "\n",
    "2. **Lösung des Polynoms**: Die Eigenwerte $ \\lambda $ sind die Lösungen dieses Polynoms. In vielen Fällen kann dies komplexe oder mehrfache Lösungen beinhalten.\n",
    "\n",
    "3. **Eigenvektoren finden**: Nachdem die Eigenwerte bekannt sind, werden die entsprechenden Eigenvektoren durch Lösen des Systems linearer Gleichungen $ (A - \\lambda I)v = 0 $ für jeden Eigenwert $ \\lambda $ gefunden.\n",
    "\n",
    "### Beispiel\n",
    "\n",
    "Betrachten Sie die Matrix $A$:\n",
    "\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "3 & 0 \\\\\n",
    "-9 & 6\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "#### Bestimmung des charakteristischen Polynoms\n",
    "\n",
    "Setzt man $A - \\lambda I$ ein, erhält man:\n",
    "\n",
    "$$\n",
    "A - \\lambda I = \\begin{pmatrix}\n",
    "3 - \\lambda & 0 \\\\\n",
    "-9 & 6 - \\lambda\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Die Determinante dieser Matrix ist:\n",
    "\n",
    "$$\n",
    "\\text{det}(A - \\lambda I) = (3 - \\lambda)(6 - \\lambda) - (0 \\cdot (-9)) = \\lambda^2 - 9\\lambda + 18\n",
    "$$\n",
    "\n",
    "#### Lösung des charakteristischen Polynoms\n",
    "\n",
    "Die Eigenwerte $\\lambda$ sind die Lösungen des charakteristischen Polynoms $\\lambda^2 - 9\\lambda + 18 = 0$. Die Lösungen sind $\\lambda_1 = 3$ und $\\lambda_2 = 6$.\n",
    "\n",
    "#### Bestimmung der Eigenvektoren\n",
    "\n",
    "Für jeden Eigenwert $\\lambda$ löst man das System $(A - \\lambda I)v = 0$, um den entsprechenden Eigenvektor $v$ zu finden.\n",
    "\n",
    "- Für $\\lambda_1 = 3$:\n",
    "\n",
    "$$\n",
    "(A - 3I)v = \\begin{pmatrix}\n",
    "0 & 0 \\\\\n",
    "-9 & 3\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "x \\\\\n",
    "y\n",
    "\\end{pmatrix}\n",
    "= \\begin{pmatrix}\n",
    "0 \\\\\n",
    "0\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Dies führt auf den Eigenvektor $\\vec{x}_1 = \\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix}$.\n",
    "\n",
    "- Für $\\lambda_2 = 6$:\n",
    "\n",
    "$$\n",
    "(A - 6I)v = \\begin{pmatrix}\n",
    "-3 & 0 \\\\\n",
    "-9 & 0\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "x \\\\\n",
    "y\n",
    "\\end{pmatrix}\n",
    "= \\begin{pmatrix}\n",
    "0 \\\\\n",
    "0\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Dies ergibt den Eigenvektor $\\vec{x}_2 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physikalische Interpretation von Eigenwerten und Eigenvektoren <a id=\"2\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beispiel Kontext: Die elastische Hülle\n",
    "\n",
    "Stellen Sie sich eine dünnwandige, elastische Hülle vor – vergleichbar mit einem Ballon. Dieses flexibel formbare Objekt kann verschiedene Arten von Transformationen durchlaufen, darunter Drehungen, Kompressionen, Expansionen und Scherungen. In diesem interaktiven Beispiel werden Sie die Möglichkeit haben, die elastische Hülle diesen Transformationen zu unterziehen und zu beobachten, wie sich ihre Form und Orientierung im Raum dadurch verändert.\n",
    "\n",
    "### Interaktives Widget\n",
    "\n",
    "Das von uns bereitgestellte Widget ermöglicht es Ihnen, die elastische Hülle durch eine Auswahl von Transformationen zu manipulieren. Sie können zwischen Rotation, Kompression, Expansion und Scherung wählen und den Grad oder die Intensität jeder Transformation individuell anpassen. Während Sie diese Einstellungen vornehmen, beobachten Sie folgendes:\n",
    "\n",
    "- Wie ändert sich die Form der Hülle?\n",
    "- Bleibt ihr Volumen konstant oder verändert es sich?\n",
    "- Wie verändert sich die Orientierung und die Ausrichtung der Hülle im Raum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be5459d01eba4d778fee48a6891d1368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Transformation:', options=('Rotation', 'Kompression', 'Expansion',…"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def create_transformation_matrix(transformation_type, factor):\n",
    "    if transformation_type == 'Rotation':\n",
    "        # Erzeugung einer Rotationsmatrix um die z-Achse\n",
    "        theta = np.radians(factor)\n",
    "        matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n",
    "                           [np.sin(theta), np.cos(theta), 0],\n",
    "                           [0, 0, 1]])\n",
    "    elif transformation_type == 'Kompression':\n",
    "        # Erzeugung einer Skalierungsmatrix für Kompression\n",
    "        matrix = np.diag([1 - factor, 1 - factor, 1 - factor])\n",
    "    elif transformation_type == 'Expansion':\n",
    "        # Erzeugung einer Skalierungsmatrix für Expansion\n",
    "        matrix = np.diag([1 + factor, 1 + factor, 1 + factor])\n",
    "    elif transformation_type == 'Scherung':\n",
    "        # Erzeugung einer Scherungsmatrix\n",
    "        matrix = np.array([[1, factor, 0], \n",
    "                           [0, 1, 0], \n",
    "                           [factor, 0, 1]])\n",
    "    return matrix\n",
    "\n",
    "def plot_transformed_hull(transformation_type, factor):\n",
    "    # Erzeugung der ursprünglichen Hülle\n",
    "    u, v = np.mgrid[0:2*np.pi:20j, 0:np.pi:10j]\n",
    "    x = np.cos(u)*np.sin(v)\n",
    "    y = np.sin(u)*np.sin(v)\n",
    "    z = np.cos(v)\n",
    "\n",
    "    # Anwendung der Transformation\n",
    "    transformation_matrix = create_transformation_matrix(transformation_type, factor)\n",
    "    transformed_coordinates = np.dot(transformation_matrix, np.vstack([x.flatten(), y.flatten(), z.flatten()]))\n",
    "\n",
    "    # Umwandlung der Koordinaten zurück in 3D\n",
    "    x_transformed, y_transformed, z_transformed = transformed_coordinates.reshape(3, *x.shape)\n",
    "\n",
    "    eigvals, eigvecs = np.linalg.eig(transformation_matrix)\n",
    "    \n",
    "    # Visualisierung\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot_surface(x_transformed, y_transformed, z_transformed, color='blue', alpha=0.6)\n",
    "    ax.plot_surface(x, y, z, color='red', alpha=0.3)\n",
    "    ax.set_xlabel('X axis')\n",
    "    ax.set_ylabel('Y axis')\n",
    "    ax.set_zlabel('Z axis')\n",
    "    plt.title(f'Transformation: {transformation_type} (Faktor: {factor})')\n",
    "    print(\"Eigenwerte: \\n\", np.round(np.real(eigvals),5))\n",
    "    print(\"Egenvektoren: \\n\", np.round(np.real(eigvecs),5))\n",
    "    plt.show()\n",
    "\n",
    "# Erstellen der Widgets\n",
    "transformation_dropdown = widgets.Dropdown(options=['Rotation', 'Kompression', 'Expansion', 'Scherung'], value='Rotation', description='Transformation:')\n",
    "factor_slider = widgets.FloatSlider(value=0, min=0, max=1, step=0.05, description='Faktor:')\n",
    "\n",
    "# Anzeige des Widgets\n",
    "widgets.interactive(plot_transformed_hull, transformation_type=transformation_dropdown, factor=factor_slider)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: black; background-color: powderblue; margin: 10px auto; padding: 10px; border-radius: 10px\">\n",
    "    <p style=\"font-size:12pt; text-align:center; color: black; background-color: lightskyblue; margin: 10px auto; padding: 10px; border-radius: 10px\" id=\"1\"><b>Aufgabe 1</b></p>\n",
    "\n",
    "Erkunden Sie die Unterschiede zwischen Rotation, Kompression, Expansion und Scherung anhand des interaktiven Widgets. Beobachten Sie, wie sich die Eigenwerte und Eigenvektoren in jedem Fall verhalten.\n",
    "\n",
    "- Nutzen Sie das Widget, um verschiedene Rotationen, Kompressionen, Expansionen und Scherungen anzuwenden.\n",
    "- Beobachten Sie die Veränderungen in den Eigenwerten und Eigenvektoren.\n",
    "- Vergleichen Sie die Ergebnisse der vier Transformationen. Wie unterscheiden sich die Eigenwerte und Eigenvektoren bei diesen Transformationen?\n",
    "- Dokumentieren Sie Ihre Beobachtungen und erklären Sie die Unterschiede in den Auswirkungen der verschiedenen Transformationen auf die Eigenwerte und Eigenvektoren.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details> \n",
    "<summary>Lösung</summary>\n",
    "\n",
    "### Rotation\n",
    "\n",
    "Bei einer **Rotation** der elastischen Hülle bleibt das Volumen unverändert, aber die Orientierung ändert sich.\n",
    "\n",
    "- **Eigenwerte**: Die Eigenwerte bei einer Rotation sind in der Regel komplex und liegen auf dem Einheitskreis in der komplexen Ebene, was bedeutet, dass ihre Beträge 1 sind.\n",
    "  \n",
    "- **Eigenvektoren**: Für Rotationen im 3D-Raum gibt es einen reellen Eigenvektor, der der Rotationsachse entspricht. Die anderen Eigenvektoren sind komplex.\n",
    "\n",
    "### Kompression\n",
    "\n",
    "Bei einer **Kompression** wird das Volumen der elastischen Hülle reduziert.\n",
    "\n",
    "- **Eigenwerte**: Die Eigenwerte sind kleiner als 1 und repräsentieren das Ausmaß der Volumenreduktion in den jeweiligen Achsenrichtungen.\n",
    "  \n",
    "- **Eigenvektoren**: Die Eigenvektoren zeigen in die Richtungen, entlang derer die Kompression stattfindet.\n",
    "\n",
    "### Expansion\n",
    "\n",
    "Bei einer **Expansion** wird das Volumen der elastischen Hülle vergrößert.\n",
    "\n",
    "- **Eigenwerte**: Die Eigenwerte sind größer als 1 und repräsentieren das Ausmaß der Volumenvergrößerung in den jeweiligen Achsenrichtungen.\n",
    "  \n",
    "- **Eigenvektoren**: Die Eigenvektoren weisen in die Richtungen der Expansion.\n",
    "\n",
    "### Scherung\n",
    "\n",
    "Bei einer **Scherung** ändert sich die Form der Hülle, während das Volumen unverändert bleibt.\n",
    "\n",
    "- **Eigenwerte**: Einer der Eigenwerte ist oft 1, da eine der Achsen unverändert bleibt. Die anderen Eigenwerte hängen von der Scherungsintensität ab.\n",
    "  \n",
    "- **Eigenvektoren**: Die Eigenvektoren zeigen die Richtungen an, in denen die Punkte der Hülle verschoben werden.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerische Berechnung von Eigenwerten und Eigenvektoren <a id=\"3\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Kapitel wird sich einem der zentralen Probleme der numerischen linearen Algebra zugewandt: der Berechnung von Eigenwerten und Eigenvektoren. Diese Konzepte sind nicht nur in der Theorie von großer Bedeutung, sondern auch für die praktische Anwendung in Bereichen wie der Strukturanalyse, der Schwingungsanalyse und der Datenwissenschaft unverzichtbar. Es wird mit einer Untersuchung der Potenzmethode begonnen, einem klassischen Algorithmus, der durch seine Einfachheit und Effizienz bei der Bestimmung des betragsmäßig größten Eigenwerts und des zugehörigen Eigenvektors besticht. Anschließend werden moderne Rechenwerkzeuge wie Sympy und Numpy vorgestellt und wie Sie in Python genutzt werden können, um diese und weitere Methoden zur Eigenwertberechnung zu implementieren und zu vereinfachen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potenzmethode (Power-Methode)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Potenzmethode ist ein essentielles Werkzeug in der numerischen linearen Algebra zur Bestimmung dominanter Eigenwerte und Eigenvektoren, besonders bei großen und spärlich besetzten Matrizen. Dominant beduet in diesem Sinne der größte Eigenwert einer Matrix. Der iterative Ansatz der Potenzmethode ermöglicht eine schnelle Annäherung an den größten Eigenwert und den zugehörigen Eigenvektor. Diese Methode dient oft als Basis für komplexere Eigenwertberechnungen und ist wertvoll für schnelle, effiziente Näherungen in vielfältigen Anwendungen.\n",
    "\n",
    "Im Folgenden wird das Grundverfahren der Potenzmethode detailliert betrachtet, von der Initialisierung mit einem Startvektor bis hin zur iterativen Annäherung des größten Eigenwerts.\n",
    "\n",
    "Grundverfahren\n",
    "\n",
    "1) Initialisierung:\n",
    "-  Mit einem zufälligen Startvektor $x_0$ starten (dieser muss nicht normiert sein, sollte aber nicht der Nullvektor sein).\n",
    "\n",
    "2) Iteration: Wiederhole für $k = 0, 1, 2, \\ldots $:\n",
    "   \n",
    "-   $y_{k+1} = A x_k$ \n",
    "-   $x_{k+1} = \\frac{y_{k+1}}{\\|y_{k+1}\\|}$ (Normierung des Bildvektors)\n",
    "   \n",
    "\n",
    "\n",
    "3) Der betragsmäßig größte Eigenwert $\\lambda$ kann approximiert werden durch:\n",
    "\n",
    "-   $\\lambda \\approx \\frac{y_{k+1}^T x_k}{x_k^T x_k}$\n",
    "\n",
    "Nach ausreichend vielen Iterationen konvergiert der Vektor $x$ gegen den Eigenvektor, der zum betragsmäßig größten Eigenwert von $A$ gehört.\n",
    "\n",
    "Nun sind Sie an der Reihe. Im Folgenden finden Sie ein Teil des Algorithmus und Sie sollen ihn vervollständigen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style= \"color: black;background-color: powderblue ;margin: 10 px auto; padding: 10px; border-radius: 10px\">\n",
    "    <p style=\"font-size:12pt; text-align:center; color:   black; background-color: lightskyblue ;margin: 10 px auto; padding: 10px; border-radius: 10px\" id=\"1\"><b>Aufgabe 2</b>  </p> \n",
    "\n",
    "Implementieren Sie die Methode <code>power_iteration(A,num_simulations,tol)</code>. Gehen Sie vor wie in dem oben vorgestellten Grundverfahren. Jedoch brechen Sie das Verfahren nicht nur anhand einer maximalen Anzahl an Iterationen ab, sondern auch wenn die Approximation des Eigenwerts die Toleranzgrenze unterschreitet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Betragsmäßig größter Eigenwert: -5.872983237009456\n",
      "Zugehöriger Eigenvektor: [ 0.40004313 -0.91649631]\n"
     ]
    }
   ],
   "source": [
    "def potenzmethode(A, max_iter=1000, tol=1e-6):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - A: Die Matrix, deren größter Eigenwert bestimmt werden soll.\n",
    "    - max_iter: Die maximale Anzahl der Iterationen.\n",
    "    - tol: Toleranz für die Genauigkeit der Approximation.\n",
    "\n",
    "    Returns:\n",
    "    - lambda_approx: Näherungswert für den betragsmäßig größten Eigenwert.\n",
    "    - x: Zugehöriger Eigenvektor.\n",
    "    \"\"\"\n",
    "\n",
    "    # Zufälligen Startvektor wählen\n",
    "    x = np.random.rand(A.shape[0])\n",
    "    \n",
    "    for i in range(???):\n",
    "        # Produktvektor berechnen\n",
    "        y = \n",
    "        \n",
    "        # Näherung für den Eigenwert aus dem aktuellen und dem vorherigen Vektor\n",
    "        lambda_approx = \n",
    "        \n",
    "        # Überprüfen, ob genügend nah approximiert wurde\n",
    "        if np.linalg.norm(y - lambda_approx * x) < tol:\n",
    "            break\n",
    "\n",
    "        # Vektor für die nächste Iteration normieren\n",
    "        x = \n",
    "    \n",
    "    return lambda_approx, x\n",
    "\n",
    "# Beispiel\n",
    "A = np.array([ [ 1,3], \n",
    "                [2,-5]])\n",
    "eigenwert, eigenvektor = potenzmethode(A)\n",
    "print(\"Betragsmäßig größter Eigenwert:\", eigenwert)\n",
    "print(\"Zugehöriger Eigenvektor:\", eigenvektor)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sympy und Numpy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach der Erkundung der Potenzmethode zur Annäherung von Eigenwerten und Eigenvektoren wird sich nun den Python-Bibliotheken Sympy und Numpy zugewendet. Sympy erleichtert die symbolische Berechnung und bietet genaue Lösungen, während Numpy für schnelle numerische Operationen mit Arrays und Matrizen unerlässlich ist. In diesem Kapitel werden die Anwendung dieser Werkzeuge zur praktischen Umsetzung der theoretischen Konzepte demonstriert. Dabei wird sich daruf konzentriert, wie Sympy und Numpy die Berechnungen vereinfachen und beschleunigen können."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Sympy: Symbolische Berechnung von Eigenwerten und Eigenvektoren"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sympy ist eine Python-Bibliothek, die speziell für symbolische Berechnungen entwickelt wurde. Im Gegensatz zu numerischen Methoden, die mit Annäherungen arbeiten, ermöglicht Sympy das exakte Lösen mathematischer Ausdrücke. Dies ist besonders nützlich bei der Berechnung von Eigenwerten und Eigenvektoren, wo exakte Werte oft entscheidend sind.\n",
    "\n",
    "**Grundlagen von Sympy**:\n",
    "- **Symbolische Objekte**: In Sympy werden mathematische Symbole als Objekte dargestellt, die es versuchen, Ausdrücke genau wie in der herkömmlichen Mathematik zu manipulieren.\n",
    "- **Exaktheit**: Sympy berechnet Ergebnisse exakt, was bei der Analyse von Systemen, die eine hohe Präzision erfordern, von Vorteil ist.\n",
    "\n",
    "**Eigenwerte und Eigenvektoren mit Sympy berechnen**:\n",
    "- Sympy bietet Funktionen wie `eigenvects()` und `eigenvals()`, die es ermöglichen, die Eigenvektoren und -werte einer Matrix präzise zu bestimmen.\n",
    "- Beispiel: Für eine Matrix `A` können Sie Sympy verwenden, um ihre Eigenwerte und Eigenvektoren wie folgt zu berechnen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenwerte:\n",
      "⎧5   √5     √5   5   ⎫\n",
      "⎨─ - ──: 1, ── + ─: 1⎬\n",
      "⎩2   2      2    2   ⎭\n",
      "\n",
      "Eigenvektoren:\n",
      "Eigenwert:\n",
      " 5   √5\n",
      "─ - ──\n",
      "2   2 \n",
      "Vielfachheit: 1\n",
      "Eigenvektor:\n",
      "⎡  √5   1⎤\n",
      "⎢- ── - ─⎥\n",
      "⎢  2    2⎥\n",
      "⎢        ⎥\n",
      "⎣   1    ⎦\n",
      "\n",
      "Eigenwert:\n",
      " √5   5\n",
      "── + ─\n",
      "2    2\n",
      "Vielfachheit: 1\n",
      "Eigenvektor:\n",
      "⎡  1   √5⎤\n",
      "⎢- ─ + ──⎥\n",
      "⎢  2   2 ⎥\n",
      "⎢        ⎥\n",
      "⎣   1    ⎦\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sympy as sp\n",
    "import numpy as np\n",
    "\n",
    "# Definieren einer Matrix\n",
    "A = sp.Matrix([[2, 1], [1, 3]])\n",
    "\n",
    "# Berechnung der Eigenwerte und Eigenvektoren\n",
    "eigenwerte = A.eigenvals()\n",
    "eigenvektoren = A.eigenvects()\n",
    "\n",
    "# Ausgabe der Eigenwerte\n",
    "print(\"Eigenwerte:\")\n",
    "print(sp.pretty(eigenwerte))\n",
    "\n",
    "eigenvektoren_sympy = []\n",
    "eigenwerte_sympy = []\n",
    "# Ausgabe der Eigenvektoren\n",
    "print(\"\\nEigenvektoren:\")\n",
    "for val, mult, vec in eigenvektoren:\n",
    "    print(f\"Eigenwert:\\n {sp.pretty(val)}\")\n",
    "    eigenwerte_sympy.append(float(val))\n",
    "    print(f\"Vielfachheit: {mult}\")\n",
    "    print(\"Eigenvektor:\")\n",
    "    print(sp.pretty(vec[0]))\n",
    "    eigenvektoren_sympy.append(np.array(vec[0]).astype(np.float64))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erklärung der Ausgabe\n",
    "\n",
    "\n",
    "Ausgabe für die Eigenwerte der Matrix. Vielfachheit beschreibt wie oft der Eigenwert vorhanden ist:\n",
    "\n",
    "```text\n",
    "Eigenwerte:\n",
    "⎧5   √5     √5   5   ⎫\n",
    "⎨─ - ──: 1, ── + ─: 1⎬\n",
    "⎩2   2      2    2   ⎭\n",
    "\n",
    "```\n",
    "\n",
    "Ausgabe der Eigenvektoren mit den zugehörigen Eigenwerten. Hierbei wieder mit der Vielfachheit.\n",
    "\n",
    "```text\n",
    "Eigenvektoren:\n",
    "Eigenwert:\n",
    " 5   √5\n",
    "─ - ──\n",
    "2   2 \n",
    "Vielfachheit: 1\n",
    "Eigenvektor:\n",
    "⎡  √5   1⎤\n",
    "⎢- ── - ─⎥\n",
    "⎢  2    2⎥\n",
    "⎢        ⎥\n",
    "⎣   1    ⎦\n",
    "\n",
    "Eigenwert:\n",
    " √5   5\n",
    "── + ─\n",
    "2    2\n",
    "Vielfachheit: 1\n",
    "Eigenvektor:\n",
    "⎡  1   √5⎤\n",
    "⎢- ─ + ──⎥\n",
    "⎢  2   2 ⎥\n",
    "⎢        ⎥\n",
    "⎣   1    ⎦\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy: Numerische Berechnung von Eigenwerten und Eigenvektoren"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem sich mit den symbolischen Berechnungen von Eigenwerten und Eigenvektoren mit Sympy befasst wurde, wird sich nun Numpy zugewendet. Numpy ist besonders für seine Fähigkeit zur effizienten Handhabung großer Datenmengen und Matrizen bekannt und spielt eine zentrale Rolle in vielen Bereichen der Datenanalyse und numerischen Simulation.\n",
    "\n",
    "**Grundlagen von Numpy**:\n",
    "- **Effizienz und Geschwindigkeit**: Numpy nutzt optimierte C- und Fortran-Bibliotheken, um Operationen auf großen Arrays und Matrizen schnell durchzuführen.\n",
    "- **Einfachheit**: Numpy bietet eine intuitive Schnittstelle für komplexe numerische Operationen, was die Implementierung von Algorithmen erleichtert.\n",
    "\n",
    "\n",
    "**Berechnung von Eigenwerten und Eigenvektoren mit Numpy**:\n",
    "- Numpy bietet die Funktion `numpy.linalg.eig()`, die sowohl die Eigenwerte als auch die Eigenvektoren einer Matrix berechnet.\n",
    "- Beispiel: Für eine gegebene Matrix `A` können Sie Numpy verwenden, um ihre Eigenwerte und Eigenvektoren wie folgt zu berechnen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenwerte:  [1.38196601 3.61803399]\n",
      "Eigenvektoren:  [[-0.85065081 -0.52573111]\n",
      " [ 0.52573111 -0.85065081]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Definieren einer Matrix\n",
    "A = np.array([[2, 1], [1, 3]])\n",
    "\n",
    "# Berechnung der Eigenwerte und Eigenvektoren\n",
    "eigenwerte_numpy, eigenvektoren_numpy = np.linalg.eig(A)\n",
    "print(\"Eigenwerte: \", eigenwerte_numpy)\n",
    "print(\"Eigenvektoren: \", eigenvektoren_numpy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style= \"color: black;background-color: powderblue ;margin: 10 px auto; padding: 10px; border-radius: 10px\">\n",
    "    <p style=\"font-size:12pt; text-align:center; color:   black; background-color: lightskyblue ;margin: 10 px auto; padding: 10px; border-radius: 10px\" id=\"1\"><b>Aufgabe 3</b>  </p> \n",
    "    \n",
    "**Ziel**: Untersuchen Sie, wie Sympy und Numpy bei der Berechnung von Eigenwerten und Eigenvektoren einer Matrix in Bezug auf Genauigkeit und Geschwindigkeit abschneiden.\n",
    "\n",
    "**Aufgaben**:\n",
    "1. **Matrixdefinition**: Erstellen Sie eine 10x10-Matrix mit zufälligen Werten.\n",
    "\n",
    "2. **Berechnung mit Sympy**:\n",
    "   - Benutzen Sie Sympy, um die Eigenwerte und Eigenvektoren der Matrix zu berechnen. Messen Sie die Zeit mit `%%time`.\n",
    "\n",
    "3. **Berechnung mit Numpy**:\n",
    "   - Konvertieren Sie dieselbe Matrix in ein Numpy-Array und wiederholen Sie die Berechnung. Verwenden Sie `%%time` zur Zeitmessung.\n",
    "\n",
    "4. **Analyse**:\n",
    "   - Vergleichen Sie die Genauigkeit und Berechnungsdauer beider Methoden.\n",
    "   - Diskutieren Sie die Vor- und Nachteile von Sympy und Numpy in diesem Kontext.\n",
    "\n",
    "Fassen Sie Ihre Ergebnisse zusammen und geben Sie Empfehlungen, wann Sympy oder Numpy vorzuziehen ist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "eigenwerte = A.eigenvals()\n",
    "eigenvektoren = A.eigenvects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "eigenwerte_numpy, eigenvektoren_numpy = np.linalg.eig(np.array(A).astype(np.float64))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singulärwertzerlegung (SVD) <a id=\"4\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Singulärwertzerlegung (SVD von Singular value Decomposition) ist ein Schlüsselkonzept in der linearen Algebra mit weitreichenden Anwendungen in der modernen Datenanalyse. Besonders in der Bildkompression zeigt sich ihr praktischer Nutzen: Die SVD ermöglicht es, Bilder effizient zu komprimieren, indem sie die wichtigsten Informationen in einer verdichteten Form darstellt. Im Folgenden wird die Theorie hinter der SVD erforscht und ihre Anwendung in der Bildkompression beleuchtet.\n",
    "\n",
    "### Theoretische Grundlagen\n",
    "Die SVD zerlegt eine beliebige unitäre $ m \\times n $-Matrix $ A $ in drei spezielle Matrizen:\n",
    "\n",
    "1. **Orthogonale Matrix $ U $**: Diese $ m \\times m $-Matrix enthält die sog. linken singulären Vektoren von $ A $. Die Spaltenvektoren von $ U $ sind orthonormal, was bedeutet, dass sie sowohl orthogonal (senkrecht zueinander) als auch normiert (mit einer Länge von 1) sind.\n",
    "\n",
    "2. **Diagonalmatrix $ \\Sigma $**: Diese $ m \\times n $-Matrix enthält die singulären Werte von $ A $ entlang der Diagonalen. Diese Werte sind nicht-negativ und werden üblicherweise in absteigender Reihenfolge sortiert. Die Anzahl der von null verschiedenen singulären Werte gibt den Rang von $ A $ an.\n",
    "\n",
    "3. **Orthogonale Matrix $ V^T $**: Diese $ n \\times n $-Matrix enthält die rechten singulären Vektoren von $ A $. $ V^T $ ist die Transponierte der Matrix $ V $, deren Spalten die rechten singulären Vektoren sind und ebenfalls orthonormal sind.\n",
    "\n",
    "### Mathematische Definition\n",
    "Die SVD einer Matrix $ A $ wird mathematisch als $ A = U \\Sigma V^T $ ausgedrückt. Hierbei ist:\n",
    "\n",
    "- $ A $: Die ursprüngliche $ m \\times n $-Matrix.\n",
    "- $ U $: Eine $ m \\times m $-orthogonale Matrix.\n",
    "- $ \\Sigma $: Eine $ m \\times n $-Diagonalmatrix mit den singulären Werten von $ A $.\n",
    "- $ V^T $: Die Transponierte einer $ n \\times n $-orthogonalen Matrix $ V $.\n",
    "\n",
    "Diese Zerlegung existiert für jede rechteckige Matrix. Die singulären Werte in $ \\Sigma $ zeigen Signifikanz der entsprechenden singulären Vektoren in $ U $ und $ V^T $. In Anwendungen wie der Bildkompression werden die größten singulären Werte als die wichtigsten betrachtet, da sie den größten Beitrag zur Struktur des Bildes leisten."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigenwerte und Eigenvektoren werden besonders wichtig im Kontext der Singulärwertzerlegung (SVD), wenn man die Beziehung zwischen der SVD und der Eigenwertzerlegung (EVD) von bestimmten abgeleiteten Matrizen betrachtet. Hier sind die Schlüsselpunkte, bei denen Eigenwerte und Eigenvektoren eine zentrale Rolle spielen:\n",
    "\n",
    "**Beziehung zwischen SVD und EVD**: \n",
    "\n",
    "Die Singulärwertzerlegung einer Matrix $ A $ und die Eigenwertzerlegung der Matrizen $ A^TA $ und $ AA^T $ sind eng miteinander verbunden. Insbesondere sind die rechten singulären Vektoren von $ A $ (die Spalten von $ V $ in der Zerlegung $ A = U \\Sigma V^T $) die Eigenvektoren von $ A^TA $, und die linken singulären Vektoren von $ A $ (die Spalten von $ U $) sind die Eigenvektoren von $ AA^T $.\n",
    "\n",
    "**Berechnung von Singulärwerten**: \n",
    "\n",
    "Die Singulärwerte in $ \\Sigma $ sind die Quadratwurzeln der Eigenwerte von $ A^TA $ (oder $ AA^T $), die immer nichtnegativ sind. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style= \"color: black;background-color: powderblue ;margin: 10 px auto; padding: 10px; border-radius: 10px\">\n",
    "    <p style=\"font-size:12pt; text-align:center; color:   black; background-color: lightskyblue ;margin: 10 px auto; padding: 10px; border-radius: 10px\" id=\"1\"><b>Aufgabe 4</b>  </p> \n",
    "    \n",
    "\n",
    "Sie haben einen Codeabschnitt, der eine symmetrische, positiv definite Matrix `A` aus einer zufällig generierten Matrix `B` erstellt. Ihre Aufgabe ist es, den Code zu vervollständigen, um die Eigenwertzerlegung der Matrizen `A^TA` und `AA^T` durchzuführen und anschließend die Matrix mit einer variablen Anzahl von Singulärwerten zu rekonstruieren. Folgende Schritte sind zu vervollständigen:\n",
    "\n",
    "1. **Berechnung von $ A^TA $ und $ AA^T $:**\n",
    "   - Ergänzen Sie den Code, um die Produkte $ A^TA $ und $ AA^T $ zu berechnen.\n",
    "\n",
    "2. **Eigenwertzerlegung:**\n",
    "   - Vervollständigen Sie den Code für die Eigenwertzerlegung der Matrizen $ A^TA $ und $ AA^T $.\n",
    " \n",
    "\n",
    "3. **Implementierung der `reconstruct_image` Methode:**\n",
    "\n",
    "    - **Eingabeparameter:** Die Methode sollte vier Parameter akzeptieren:\n",
    "    - `U`: Die Matrix der linken Singulärvektoren (aus der Eigenwertzerlegung von $ AA^T $).\n",
    "    - `S`: Die Singulärwerte (positive Quadratwurzeln der Eigenwerte von $ A^TA $ oder $ AA^T $).\n",
    "    - `Vt`: Die transponierte Matrix der rechten Singulärvektoren (aus der Eigenwertzerlegung von $ A^TA $).\n",
    "    - `num_singular_values`: Die Anzahl der zu verwendenden Singulärwerte.\n",
    "\n",
    "    - **Rekonstruktionslogik:**\n",
    "    - Erstellen Sie eine Diagonalmatrix `S_reconstructed` mit den ersten `num_singular_values` Singulärwerten.\n",
    "    - Rekonstruieren Sie das Bild durch Multiplikation von `U`, `S_reconstructed` und `Vt`.\n",
    "\n",
    "    - **Rückgabewert:** Die Methode sollte die rekonstruierte Matrix/Bild zurückgeben.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5a88aecf9e455c89aebe42f1407bf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='k', max=20, min=1), Output()), _dom_classes=('widget-int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot(k)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Erstellen einer zufälligen Matrix B\n",
    "B = np.random.rand(20, 20)\n",
    "\n",
    "# Konstruktion einer symmetrischen und positiv definiten Matrix A = B^T * B\n",
    "A = np.dot(B.T, B)\n",
    "\n",
    "# Skalierung der Matrix auf den Bereich 0 bis 150\n",
    "min_val = A.min()\n",
    "max_val = A.max()\n",
    "normalized_matrix = (A - min_val) / (max_val - min_val)\n",
    "A = normalized_matrix * 150 \n",
    "\n",
    "# Berechnen von A^T * A und A * A^T\n",
    "ATA =  # ???\n",
    "AAT =  # ???\n",
    "\n",
    "# Eigenwertzerlegung von A^TA und AA^T\n",
    "eigenvalues_ATA, eigenvectors_ATA = # ???\n",
    "eigenvalues_AAT, eigenvectors_AAT =  # ???\n",
    "\n",
    "# Sortierung der Eigenwerte und Eigenvektoren\n",
    "sorted_indices_ATA = np.argsort(eigenvalues_ATA)[::-1]\n",
    "sorted_eigenvalues_ATA = eigenvalues_ATA[sorted_indices_ATA]\n",
    "sorted_eigenvectors_ATA = eigenvectors_ATA[:, sorted_indices_ATA]\n",
    "\n",
    "sorted_indices_AAT = np.argsort(eigenvalues_AAT)[::-1]\n",
    "sorted_eigenvalues_AAT = eigenvalues_AAT[sorted_indices_AAT]\n",
    "sorted_eigenvectors_AAT = eigenvectors_AAT[:, sorted_indices_AAT]\n",
    "\n",
    "# Entfernung aller Eigenwerte kleiner als 0\n",
    "singular_values = np.sqrt(sorted_eigenvalues_ATA[sorted_eigenvalues_ATA > 0])\n",
    "\n",
    "# Funktion zur Rekonstruktion des Bildes mit einer gegebenen Anzahl von Singulärwerten\n",
    "def reconstruct_image(U, S, Vt, num_singular_values): # ???\n",
    "    S_reconstructed = np.zeros((U.shape[0], Vt.shape[0]))\n",
    "    np.fill_diagonal(S_reconstructed, S[:num_singular_values])\n",
    "    # multiplizieren Sie hier S_reconstructed mit Vt mithilfe von np.dot, achten Sie hierbei dass Sie nur die Anzahl der num_singular_values verwenden\n",
    "    S_Vt =\n",
    "    # multiplizieren Sie hier U mit S_Vt mithilfe von np.dot, achten Sie hierbei dass Sie nur die Anzahl der num_singular_values verwenden\n",
    "    U_S_Vt =\n",
    "    return U_S_Vt\n",
    "\n",
    "def plot(k):\n",
    "    # Rekonstruktion des Bildes und Visualisierung\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    # Originalbild anzeigen\n",
    "    axes[0].imshow(A,cmap=\"jet\")\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Rekonstruierte Bilder anzeigen\n",
    "    reconstructed_img = reconstruct_image(sorted_eigenvectors_AAT, singular_values, sorted_eigenvectors_ATA.T, k)\n",
    "    axes[1].imshow(reconstructed_img,cmap=\"jet\")\n",
    "    axes[1].set_title(f'k = {k}')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create a slider to control the angle\n",
    "b_slider = widgets.IntSlider(min=1, max=20, step=1, value=1)\n",
    "interact(plot, k=b_slider)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bildkompression\n",
    "\n",
    "**Integration der SVD in Numpy für Bildkompression**\n",
    "\n",
    "Nach der Betrachtung der Singulärwertzerlegung (SVD) und ihrer Anwendung zur Eigenwertberechnung mit Numpy wird nun Numpys eigene SVD-Funktion betrachtet. Diese ist speziell für die effiziente Berechnung der SVD optimiert und bietet durch in der Bibliothek implementierte Algorithmen eine erhöhte Genauigkeit.\n",
    "\n",
    "Die integrierte SVD-Methode von Numpy ist besonders nützlich in der Bildkompression. Hier geht es darum, die wichtigen Informationen eines Bildes in einer komprimierten Form zu speichern, um Speicherplatz zu sparen. Die SVD ermöglicht dies, indem sie das Bild in drei Matrizen zerlegt: $ U $, $ \\Sigma $ und $ V^T $.\n",
    "\n",
    "**Speicherung der Komponenten**\n",
    "\n",
    "Für die Bildkompression ist es oft nicht notwendig, alle Komponenten der Zerlegung zu speichern. Stattdessen konzentriert man sich auf die größten Singulärwerte in $ \\Sigma $ und die entsprechenden Spalten von $ U $ und Zeilen von $ V^T $. Diese reduzierte Darstellung behält die wesentlichen Merkmale des Bildes bei, während sie signifikant weniger Speicherplatz benötigt.\n",
    "\n",
    "**Beispiel: Bildkompression mit SVD**\n",
    "\n",
    "Betrachte man ein Bild mit einer Auflösung von 1000x1000 Pixeln. Die Anwendung der SVD könnte zeigen, dass nur die ersten 100 Singulärwerte einen signifikanten Beitrag zum Bild liefern. Indem nur diese Werte sowie die entsprechenden 100 Spalten von $ U $ und 100 Zeilen von $ V^T $ gespeichert werden, kann man das Bild effizient komprimieren. Diese Methode reduziert die Datenmenge erheblich, wobei die wesentlichen Informationen des Bildes erhalten bleiben.\n",
    "\n",
    "\n",
    "In dem kommenden Abschnitt werden die Anwendung der integrierten SVD-Methode von Numpy für die Bildkompression praktisch demonstriert. Hierbei werden Sie die SVD auf ein Bild anwenden und das Bild  mit einer verschiedenen Anzahl an Singulärwerten plotten. Sie werden beobachten, dass oftmals nur eine niedrige Anzahl an Singulärwerten benötigt werden, um ein Bild darzustellen.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style= \"color: black;background-color: powderblue ;margin: 10 px auto; padding: 10px; border-radius: 10px\">\n",
    "    <p style=\"font-size:12pt; text-align:center; color:   black; background-color: lightskyblue ;margin: 10 px auto; padding: 10px; border-radius: 10px\" id=\"1\"><b>Aufgabe 5</b>  </p> \n",
    "    \n",
    "Der Code lädt ein Bild und führt die Singularwertzerlegung mit Numpy durch. Ihre Hauptaufgabe besteht darin, den Code zu vervollständigen, um das Bild unter Verwendung einer reduzierten Anzahl von Singulärwerten zu rekonstruieren.\n",
    "\n",
    "**Schritte:**\n",
    "\n",
    "1. **Durchführung der SVD:**\n",
    "   - Vervollständigen Sie den Code, um die Singularwertzerlegung des Bildes durchzuführen.\n",
    "   - Verwenden Sie dafür die Methode `np.linalg.svd()`\n",
    "\n",
    "2. **Implementierung der `reconstruct_image` Methode:**\n",
    "   - Implementieren Sie die Logik, wie aus der vorherigen Aufgabe, um das Bild mit den `k` größten Singulärwerten zu rekonstruieren.\n",
    "\n",
    "**Implementierung der `reconstruct_image` Methode:**\n",
    "\n",
    "- Die Funktion sollte die ersten `k` Spalten von `U` und die ersten `k` Zeilen von `VT` verwenden.\n",
    "- Erstellen Sie eine Diagonalmatrix `Sigma_reduced` mit den ersten `k` Singulärwerten.\n",
    "- Rekonstruieren Sie das Bild durch Multiplikation von `U[:, :k]`, `Sigma_reduced` und `VT[:k, :]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('StarryNight.jpg').convert('L')\n",
    "image_matrix = np.array(image)\n",
    "\n",
    "#  SVD durchführen mit numpy ???\n",
    "U, Sigma, VT = \n",
    "\n",
    "# Funktion zur Rekonstruktion des Bildes mit einer gegebenen Anzahl von Singulärwerten\n",
    "def reconstruct_image(U, Sigma, VT, num_singular_values): # ???\n",
    "    S_reconstructed = np.zeros((num_singular_values, num_singular_values))\n",
    "    np.fill_diagonal(S_reconstructed, Sigma[:num_singular_values])\n",
    "    # multiplizieren Sie hier S_reconstructed mit VT mithilfe von np.dot, achten Sie hierbei dass Sie nur die Anzahl der num_singular_values verwenden\n",
    "    S_Vt =\n",
    "    # multiplizieren Sie hier U mit S_Vt mithilfe von np.dot, achten Sie hierbei dass Sie nur die Anzahl der num_singular_values verwenden\n",
    "    U_S_Vt =\n",
    "    return U_S_Vt\n",
    "\n",
    "# Bild mit verschiedener Anzahl an singulärwerten rekonstruieren\n",
    "k_values = [5, 20, 50,100,len(Sigma)]  \n",
    "fig, axes = plt.subplots(1, len(k_values) + 1, figsize=(15, 6))\n",
    "\n",
    "axes[0].imshow(image_matrix, cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "for i, k in enumerate(k_values):\n",
    "    reconstructed = reconstruct_image(U, Sigma, VT, k)\n",
    "    axes[i + 1].imshow(reconstructed, cmap='gray')\n",
    "    axes[i + 1].set_title(f'k = {k}')\n",
    "    axes[i + 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spur und Eigenwerte <a id=\"5\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für eine gegebene quadratische Matrix $ A $ der Größe $ n \\times n $, gilt:\n",
    "\n",
    "1. **Eigenwerte von $ A $**: Die Eigenwerte $ \\lambda_1, \\lambda_2, \\ldots, \\lambda_n $ von $ A $ sind die Lösungen der charakteristischen Gleichung $ \\text{det}(A - \\lambda I) = 0 $, wobei $ I $ die Einheitsmatrix ist.\n",
    "\n",
    "2. **Spur von $ A $**: Die Spur $\\text{Tr}(A)$ ist die Summe der Diagonalelemente von $ A $, also $ \\text{Tr}(A) = a_{11} + a_{22} + \\ldots + a_{nn} $.\n",
    "\n",
    "\n",
    "\n",
    "### Beziehung\n",
    "\n",
    "Die Summe der Eigenwerte von $ A $ ist gleich der Spur von $ A $. Das heißt:\n",
    "\n",
    "$$\n",
    "\\lambda_1 + \\lambda_2 + \\ldots + \\lambda_n = \\text{Tr}(A)\n",
    "$$\n",
    "\n",
    "Diese Beziehung gilt unabhängig davon, ob die Eigenwerte reell oder komplex sind. Es ist wichtig zu beachten, dass dies die Summe der Eigenwerte ist, nicht notwendigerweise die Eigenwerte selbst.\n",
    "\n",
    "Die Beziehung zwischen der Summe der Eigenwerte einer Matrix und ihrer Spur lässt sich auch durch die Eigenschaften der Determinante und der Spur im Kontext der linearen Algebra verstehen, insbesondere durch die Nutzung der Ähnlichkeit von Matrizen. Hier ist ein alternativer Weg, um diese Beziehung zu erklären:\n",
    "\n",
    "### Jordan-Normalform\n",
    "\n",
    "Jede quadratische Matrix $A$ kann in eine ähnliche Matrix umgeformt werden, die in ihrer Jordan-Normalform vorliegt. Das bedeutet, dass es eine invertierbare Matrix $P$ gibt, so dass $J = P^{-1}AP$ eine Jordan-Matrix ist. Die Diagonalelemente von $J$ sind die Eigenwerte von $A$, und die Spur einer Matrix bleibt bei einer Ähnlichkeitstransformation unverändert.\n",
    "\n",
    "### Spur und Ähnlichkeitstransformation\n",
    "\n",
    "Die Spur einer Matrix ändert sich nicht unter einer Ähnlichkeitstransformation. Das heißt, $\\text{Tr}(A) = \\text{Tr}(J)$. Da die Spur die Summe der Diagonalelemente ist und die Diagonalelemente von $J$ die Eigenwerte $\\lambda_i$ sind, folgt, dass $\\text{Tr}(A) = \\lambda_1 + \\lambda_2 + \\ldots + \\lambda_n$.\n",
    "\n",
    "### Determinante und das charakteristische Polynom\n",
    "\n",
    "Die Determinante von $(A - \\lambda I)$ gibt das charakteristische Polynom, dessen Wurzeln die Eigenwerte sind. Die Entwicklung des charakteristischen Polynoms zeigt, dass der Term mit $\\lambda^{n-1}$ durch die Spur der Matrix beeinflusst wird, was darauf hinweist, dass die lineare Summe der Eigenwerte (die Wurzeln des Polynoms) der Spur entspricht."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style= \"color: black;background-color: powderblue ;margin: 10 px auto; padding: 10px; border-radius: 10px\">\n",
    "    <p style=\"font-size:12pt; text-align:center; color:   black; background-color: lightskyblue ;margin: 10 px auto; padding: 10px; border-radius: 10px\" id=\"1\"><b>Aufgabe 6</b>  </p> \n",
    "    \n",
    "**Teilaufgabe 1:**\n",
    "\n",
    "Implemetieren Sie die Funktion `spur(matrix)`, welche die Spur der übergebenen Matrix berechnet und diese auf Gleicheit mit der Summe der Eigenwerte der Matrix vergleicht.\n",
    "\n",
    "**Teilaufgabe 2:**\n",
    "\n",
    "Konstruieren Sie eine Matrix mit den Eigenwerten $\\lambda_1 = 1, \\lambda_2 = 5$ und $\\lambda_3 = 4$ und überprüfen Sie die Matrix mit der Methode aus Teilaufgabe 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def spur(matrix):\n",
    "    \n",
    "\n",
    "A = np.array([[2, 0,0], [0, 3,0],[0,0,1]])\n",
    "\n",
    "spur(A)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "06e9f68a5fd931671a9d7f18b4810587644282b910ee1cd6b3f97fe455d95177"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
